{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "import torch\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import download\n",
    "\n",
    "\n",
    "#For BARD\n",
    "from transformers import pipeline\n",
    "\n",
    "#For mT5-multilingual-XLSum\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#article 1\n",
    "ARTICLE1 = '''New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
    "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
    "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
    "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
    "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
    "2010 marriage license application, according to court documents.\n",
    "Prosecutors said the marriages were part of an immigration scam.\n",
    "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
    "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
    "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
    "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
    "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
    "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
    "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
    "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
    "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
    "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.'''\n",
    "\n",
    "reference1 = '''Liana Barrientos, 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
    "2010 marriage license application, according to court documents.\n",
    "Prosecutors said the marriages were part of an immigration scam.\n",
    "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(Article,summ_txt):\n",
    "    #Model 1\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "    s = summarizer(Article, max_length=130, min_length=30, do_sample=False)\n",
    "    summ_txt.append(s[0]['summary_text'])\n",
    "    \n",
    "    #Model 2\n",
    "    summarizer = pipeline(\"summarization\", model=\"philschmid/bart-large-cnn-samsum\")\n",
    "    s = summarizer(Article)\n",
    "    summ_txt.append(s[0]['summary_text'])\n",
    "    \n",
    "    #Model 3\n",
    "    summarizer = pipeline(\"summarization\", model=\"Falconsai/text_summarization\")\n",
    "    s = summarizer(Article)\n",
    "    summ_txt.append(s[0]['summary_text'])\n",
    "    \n",
    "    #Model 4\n",
    "    summarizer = pipeline(\"summarization\", model=\"knkarthick/MEETING_SUMMARY\")\n",
    "    s = summarizer(Article)\n",
    "    summ_txt.append(s[0]['summary_text'])\n",
    "    \n",
    "    #Model 5\n",
    "    summarizer = pipeline(\"summarization\", model=\"lidiya/bart-large-xsum-samsum\")\n",
    "    s = summarizer(Article)\n",
    "    summ_txt.append(s[0]['summary_text'])\n",
    "    \n",
    "    return (summ_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Liana Barrientos, 39, is charged with two counts of \"offering a false instrument for filing in the first degree\" In total, she has been married 10 times, with nine of her marriages occurring between 1999 and 2002. If convicted, she faces up to four years in prison.',\n",
       " 'Liana Barrientos, 39, has been married 10 times between 1999 and 2002 in New York, Westchester County, Long Island, New Jersey or the Bronx. She has pleaded not guilty to two criminal counts of \"offering a false instrument for filing in the first degree\" on Friday.',\n",
       " 'Liana Barrientos, now 39, is facing two criminal counts of \"offering a false instrument\" Prosecutors said the marriages were part of an immigration scam . In total, she has been married 10 times, with nine of her marriages occurring between 1999 and 2002 .',\n",
       " 'Liana Barrientos has been married 10 times in 10 years, sometimes only within two weeks of each other. She is accused of faking her marriages as part of an immigration scam.',\n",
       " 'Liana Barrientos has been married 10 times in 10 different places in New York, sometimes within two weeks of each other. She is facing two criminal counts of offering a false instrument for filing in the first degree.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = []\n",
    "models(ARTICLE1,summary)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity for Hypothesis 1: 0.4429\n",
      "Jaccard Similarity for Hypothesis 2: 0.2949\n",
      "Jaccard Similarity for Hypothesis 3: 0.4000\n",
      "Jaccard Similarity for Hypothesis 4: 0.2143\n",
      "Jaccard Similarity for Hypothesis 5: 0.2857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\SUNIL\n",
      "[nltk_data]     KUMAR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44285714285714284,\n",
       " 0.2948717948717949,\n",
       " 0.4,\n",
       " 0.21428571428571427,\n",
       " 0.2857142857142857]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources if not already downloaded\n",
    "download('punkt')\n",
    "\n",
    "# Tokenize the text into words\n",
    "reference_tokens = set(word_tokenize(reference1.lower()))\n",
    "hypotheses_tokens = [set(word_tokenize(hypo.lower())) for hypo in summary]\n",
    "\n",
    "# Calculate Jaccard similarity\n",
    "jaccard_similarity = [len(reference_tokens.intersection(tokens)) / len(reference_tokens.union(tokens)) for tokens in hypotheses_tokens]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Different number of candidates and references",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbert_score\u001b[39;00m \u001b[39mimport\u001b[39;00m score\n\u001b[1;32m----> 2\u001b[0m P, R, F1 \u001b[39m=\u001b[39m score(summary, [reference1], lang\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39men\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Print BERTScore results\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m i, f1 \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(F1):\n",
      "File \u001b[1;32mf:\\Python\\Python39\\lib\\site-packages\\bert_score\\score.py:70\u001b[0m, in \u001b[0;36mscore\u001b[1;34m(cands, refs, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, lang, return_hash, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscore\u001b[39m(\n\u001b[0;32m     22\u001b[0m     cands,\n\u001b[0;32m     23\u001b[0m     refs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     use_fast_tokenizer\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     37\u001b[0m ):\n\u001b[0;32m     38\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m    BERTScore metric.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39m                  the *best* score among all references.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(cands) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(refs), \u001b[39m\"\u001b[39m\u001b[39mDifferent number of candidates and references\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m     \u001b[39massert\u001b[39;00m (\n\u001b[0;32m     73\u001b[0m         lang \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m model_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39mEither lang or model_type should be specified\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m     ref_group_boundaries \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Different number of candidates and references"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "P, R, F1 = score(summary, [reference1], lang=\"en\")\n",
    "\n",
    "# Print BERTScore results\n",
    "for i, f1 in enumerate(F1):\n",
    "    print(f\"BERTScore for Hypothesis {i + 1}: {f1:.4f}\")\n",
    "\n",
    "# Get the index of the summary with the highest BERTScore\n",
    "best_summary_index = F1.index(max(F1))\n",
    "print(f\"\\nThe best summary is Hypothesis {best_summary_index + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python\\Python39\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "f:\\Python\\Python39\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "f:\\Python\\Python39\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for System Summary 1: 6.957990942521506e-232\n",
      "BLEU Score for System Summary 2: 6.995501686664742e-232\n",
      "BLEU Score for System Summary 3: 8.412065649527267e-232\n",
      "BLEU Score for System Summary 4: 0\n",
      "BLEU Score for System Summary 5: 7.337741777064293e-232\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "for i, system_summary in enumerate(summary, start=1):\n",
    "    # Tokenize the summaries\n",
    "    reference_tokens = [summary.split() for summary in reference1]\n",
    "    system_tokens = system_summary.split()\n",
    "\n",
    "    # Calculate BLEU score\n",
    "    bleu_score = sentence_bleu(reference_tokens, system_tokens)\n",
    "    print(f\"BLEU Score for System Summary {i}: {bleu_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following versions that require a different python version: 0.1.0 Requires-Python >=3.10,<4.0\n",
      "ERROR: Could not find a version that satisfies the requirement meteor (from versions: none)\n",
      "ERROR: No matching distribution found for meteor\n"
     ]
    }
   ],
   "source": [
    "! pip install meteor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
